# Credit Card Fraud Detection in R
Sambhav Shrestha



### 1. Introduction
In this project, I decide to analyze the credit card transactions data. The data can be found in https://www.kaggle.com/mlg-ulb/creditcardfraud. The goal of this project is to build a model that can detect fraud transactions. I will be using four machine learning models, Logistic Regression, Decision Trees, Random Forest, and XGBoost and compare their accuracy by using sensitivity vs specificty curve,also called Receiver Operating Characteristc (ROC) curve. We begin by importing the necessary libraries and loading data from the dataset.

### 2. Importing the libaries
```{r}
# importing the required libraries
library(dplyr)      # for data manipulation
library(ranger)     # for faster implementaion of random forests
library(caret)      # for classification and regression training
library(caTools)    # for splitting data into training and test set
library(data.table) # for converting data frame to table for faster execution
library(ggplot2)    # for basic plot
library(corrplot)   # for plotting corelation plot between elements
library(Rtsne)      # for plotting tsne model
library(ROSE)       # for rose sampling
library(pROC)       # for plotting ROC curve
library(rpart)      # for regression trees
library(rpart.plot) # for plotting decision tree
library(Rborist)    # for random forest model
library(xgboost)    # for xgboost model
```


### 3. Importing the credit card dataset 
we will convert the data frame to data table which performs much faster for analyzing big data.
```{r}
# importing the dataset
dataset <- setDT(read.csv("data/creditcard.csv"))
```


### 4. Data Exploartion
Let's explore the dataset and see if we can find anything that stands out and preprocess them for building our machine learning model.
```{r}
# exploring the credit card data
head(dataset)
tail(dataset)

# view the table from class column (0 for legit transactions and 1 for fraud)
table(dataset$Class)

# view names of colums  of dataset
names(dataset)
```
By looking at the data, we can see that there are 28 anonymous variables v1 - v28, one time column, one amount column and one label column( 0 for not fraud and 1 for fraud). We will visualize this data into histogram and bar plot to find any connection or relation between variables.

```{r}
# view summary of amount and histogram
summary(dataset$Amount)
hist(dataset$Amount)
hist(dataset$Amount[dataset$Amount < 100])

# view variance and standard deviation of amount column
var(dataset$Amount)
sd(dataset$Amount)

# check whether there are any missing values in colums
colSums(is.na(dataset))
```

### 5. Data visualization

Let's first visualize the transactions over time and see if time is an important factor to be considered for this classification.
```{r}
# visualizing the distribution of transcations across time
dataset %>%
  ggplot(aes(x = Time, fill = factor(Class))) + 
  geom_histogram(bins = 100) + 
  labs(x = "Time elapsed since first transcation (seconds)", y = "no. of transactions", title = "Distribution of transactions across time") +
  facet_grid(Class ~ ., scales = 'free_y') + theme()
```
The time vs amount histogram looks pretty similar in both transactions. Since time doesn't contribute much in fraud detection we can remove the time column from the data.


Next we check the corelation between all the variables and amount and class and see if there are any variables that corelate with each other.
```{r}
# correlation of anonymous variables with amount and class
correlation <- cor(dataset[, -1], method = "pearson")
corrplot(correlation, number.cex = 1, method = "color", type = "full", tl.cex=0.7, tl.col="black")
```
From the above graph, we can see that most of the features are not corelated.In fact, all the anonymous variables are independent to each other.


The last visualization we can observe is the visualization of transactions using t-SNE (t-Distributed Stochastic Neighbor Embedding). This helps us reduce the dimensionality of the data and find any discoverable patterns if present. If there are no patttern present, it would be difficult to train the model.
```{r}
# only use 10% of data to compute SNE and perplexity to 20
tsne_data <- 1:as.integer(0.1*nrow(dataset))
tsne <- Rtsne(dataset[tsne_data,-c(1, 31)], perplexity = 20, theta = 0.5, pca = F, verbose = F, max_iter = 500, check_duplicates = F)
classes <- as.factor(dataset$Class[tsne_data])
tsne_matrix <- as.data.frame(tsne$Y)
ggplot(tsne_matrix, aes(x = V1, y = V2)) + geom_point(aes(color = classes)) + theme_minimal() + ggtitle("t-SNE visualisation of transactions") + scale_color_manual(values = c("#E69F00", "#56B4E9"))
```
Since, most of the fraud transactions lie near the edge of the blob of data, we can use different models to differentiate fraud transactions.

### 6. Data Preprocessing

Since all the anonymous variables are standardized, we also normalize Amount with mean 0.
```{r}
# scaling the data using standardization and remove the first column (time) from the data set
dataset$Amount <- scale(dataset$Amount)
new_data <- dataset[, -c(1)]
head(new_data)

# change 'Class' variable to factor
new_data$Class <- as.factor(new_data$Class)
levels(new_data$Class) <- c("Not Fraud", "Fraud")
```


# 7. Data modeling
```{r}
# split the data into training set and test set
set.seed(101)
split <- sample.split(new_data$Class, SplitRatio = 0.8)
train_data <- subset(new_data, split == TRUE)
test_data <- subset(new_data, split == FALSE)
dim(train_data)
dim(test_data)
```

```{r}
# visualize the training data
train_data %>% ggplot(aes(x = factor(Class), y = prop.table(stat(count)), fill = factor(Class))) +
  geom_bar(position = "dodge") +
  scale_y_continuous(labels = scales::percent) +
  labs(x = 'Class', y = 'Percentage', title = 'Training Class distributions') +
  theme_grey()
```

Since the data is heavily unbalanced with 99% of non-fraudulent data, this may result in our model perfoming less accurately and being heavily baised towards non-fraudulent transactions. So, We sample the data using ROSE (Random over sampling examples), Over sampling or Down sampling method, and examine the area under ROC curve at each sampling methods

### 8. Sampling Techniques

#### Rose Sampling
```{r}
set.seed(9560)
rose_train_data <- ROSE(Class ~ ., data  = train_data)$data 

table(rose_train_data$Class) 
```

#### Up Sampling
```{r}
set.seed(90)
up_train_data <- upSample(x = train_data[, -30],
                         y = train_data$Class)
table(up_train_data$Class)  

```

#### Down Sampling
```{r}
set.seed(90)
down_train_data <- downSample(x = train_data[, -30],
                         y = train_data$Class)
table(down_train_data$Class)  

```

From the experiment, upsampling peformed slightly better than ROSE and Down Sampling. However, we will use Down Sampling to reduce the time for model training and execution. Now, we will test each models and see which one classifies the data better using ROC-AUC curve.


### 9. Logistic Regression
```{r}
# fitting the logistic model
logistic_model <- glm(Class ~ ., down_train_data, family='binomial')
summary(logistic_model)
```

lets plot the logistic model
```{r}
plot(logistic_model)
```

#### Plotting the ROC-AUC Curve
```{r}
logistic_predictions <- predict(logistic_model, test_data, type='response')
roc.curve(test_data$Class, logistic_predictions, plotit = TRUE, col = "blue")

```
From the logistic regression, we got the area under ROC Curve: 0.964


### 10. Decision Tree Model
```{r}
decisionTree_model <- rpart(Class ~ . , down_train_data, method = 'class')
predicted_val <- predict(decisionTree_model, down_train_data, type = 'class')
probability <- predict(decisionTree_model, down_train_data, type = 'prob')
rpart.plot(decisionTree_model)
```
From the decision tree model, we can see that v14 is the most important variable that separates fraud and non-fraud transactions.

### 11. Random Forest Model
```{r}
x = down_train_data[, -30]
y = down_train_data[,30]

rf_fit <- Rborist(x, y, ntree = 1000, minNode = 20, maxLeaf = 13)


rf_pred <- predict(rf_fit, test_data[,-30], ctgCensus = "prob")
prob <- rf_pred$prob

roc.curve(test_data$Class, prob[,2], plotit = TRUE, col = 'blue')

```
From the random forest model, we got area under the ROC Curve: 0.962


### 12. XGBoost Model
```{r}
set.seed(40)

#Convert class labels from factor to numeric
labels <- down_train_data$Class
y <- recode(labels, 'Not Fraud' = 0, "Fraud" = 1)

# xgb fit
xgb_fit <- xgboost(data = data.matrix(down_train_data[,-30]), 
 label = y,
 eta = 0.1,
 gamma = 0.1,
 max_depth = 10, 
 nrounds = 300, 
 objective = "binary:logistic",
 colsample_bytree = 0.6,
 verbose = 0,
 nthread = 7
)

# XGBoost predictions
xgb_pred <- predict(xgb_fit, data.matrix(test_data[,-30]))
roc.curve(test_data$Class, xgb_pred, plotit = TRUE)
```
From the XGBoost model, we got area under the ROC Curve: 0.968

### 13. Significant Variables
We can also check which variables has signigicant role in fraud detection. V14 stood out in decision tree model. Let's compare it with XGboost model.
```{r}
names <- dimnames(data.matrix(down_train_data[,-30]))[[2]]

# Compute feature importance matrix
importance_matrix <- xgb.importance(names, model = xgb_fit)
# Nice graph
xgb.plot.importance(importance_matrix[1:10,])
```
As we can see v14 has siginificant role in distinguishing the fraud and non-fraud transactions.


## 14.Conclusion:
From the above plots and models, we can clarify that XGBoost performed better than logistic and Random Forest Model, although the margin was not very high. We can also fine tune the XGBoost model to make it perform even better. It is really great how models are able to find the distinguishing features between fraud and non-fraud transactions from such a big data. 







